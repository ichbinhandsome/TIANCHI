{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1601309067183",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "import warnings\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, log_loss\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading data\n",
    "train = pd.read_csv('train.csv')\n",
    "testA = pd.read_csv('testA.csv')"
   ]
  },
  {
   "source": [
    "## EDA"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['id', 'loanAmnt', 'term', 'interestRate', 'installment', 'employmentTitle', 'homeOwnership', 'annualIncome', 'verificationStatus', 'isDefault', 'purpose', 'postCode', 'regionCode', 'dti', 'delinquency_2years', 'ficoRangeLow', 'ficoRangeHigh', 'openAcc', 'pubRec', 'pubRecBankruptcies', 'revolBal', 'revolUtil', 'totalAcc', 'initialListStatus', 'applicationType', 'title', 'policyCode', 'n0', 'n1', 'n2', 'n3', 'n4', 'n5', 'n6', 'n7', 'n8', 'n9', 'n10', 'n11', 'n12', 'n13', 'n14']\n\n['grade', 'subGrade', 'employmentLength', 'issueDate', 'earliesCreditLine']\n"
    }
   ],
   "source": [
    "numerical_fea = list(train.select_dtypes(exclude=['object']).columns)\n",
    "category_fea = list(filter(lambda x: x not in numerical_fea, list(train.columns)))\n",
    "print(numerical_fea, \"\\n\")\n",
    "print(category_fea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check variables in numerical features to judge if it is discrete or continuous\n",
    "def get_numerical_serial_fea(data,feas):\n",
    "    numerical_serial_fea = []\n",
    "    numerical_noserial_fea = []\n",
    "    for fea in feas:\n",
    "        temp = data[fea].nunique()\n",
    "        if temp <= 15:\n",
    "            numerical_noserial_fea.append(fea)\n",
    "            continue\n",
    "        numerical_serial_fea.append(fea)\n",
    "    return numerical_serial_fea,numerical_noserial_fea\n",
    "\n",
    "numerical_serial_fea,numerical_noserial_fea = get_numerical_serial_fea(train,numerical_fea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['id', 'loanAmnt', 'interestRate', 'installment', 'employmentTitle', 'annualIncome', 'postCode', 'regionCode', 'dti', 'delinquency_2years', 'ficoRangeLow', 'ficoRangeHigh', 'openAcc', 'pubRec', 'revolBal', 'revolUtil', 'totalAcc', 'title', 'n0', 'n1', 'n2', 'n3', 'n4', 'n5', 'n6', 'n7', 'n8', 'n9', 'n10', 'n13', 'n14']\n['term', 'homeOwnership', 'verificationStatus', 'isDefault', 'purpose', 'pubRecBankruptcies', 'initialListStatus', 'applicationType', 'policyCode', 'n11', 'n12']\n3    606902\n5    193098\nName: term, dtype: int64\n0    395732\n1    317660\n2     86309\n3       185\n5        81\n4        33\nName: homeOwnership, dtype: int64\n1    309810\n2    248968\n0    241222\nName: verificationStatus, dtype: int64\n0    640390\n1    159610\nName: isDefault, dtype: int64\n0     464096\n4     175433\n2      52129\n5      46276\n3      17579\n9       9238\n1       9106\n8       8657\n10      5652\n7       5373\n6       4354\n12      1363\n11       554\n13       190\nName: purpose, dtype: int64\n0.0     700076\n1.0      93639\n2.0       4566\n3.0        945\n4.0        248\n5.0         80\n6.0         23\n7.0         11\n8.0          3\n9.0          3\n12.0         1\nName: pubRecBankruptcies, dtype: int64\n0    466438\n1    333562\nName: initialListStatus, dtype: int64\n0    784586\n1     15414\nName: applicationType, dtype: int64\n1.0    800000\nName: policyCode, dtype: int64\n0.0    729682\n1.0       540\n2.0        24\n4.0         1\n3.0         1\nName: n11, dtype: int64\n0.0    757315\n1.0      2281\n2.0       115\n3.0        16\n4.0         3\nName: n12, dtype: int64\n"
    }
   ],
   "source": [
    "print(numerical_serial_fea)\n",
    "#discrete vaiables in numerical features analysis\n",
    "print(numerical_noserial_fea)\n",
    "for fea in numerical_noserial_fea:\n",
    "    print(train[fea].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['grade', 'subGrade', 'employmentLength', 'issueDate', 'earliesCreditLine']\nB    233690\nC    227118\nA    139661\nD    119453\nE     55661\nF     19053\nG      5364\nName: grade, dtype: int64\nC1    50763\nB4    49516\nB5    48965\nB3    48600\nC2    47068\nC3    44751\nC4    44272\nB2    44227\nB1    42382\nC5    40264\nA5    38045\nA4    30928\nD1    30538\nD2    26528\nA1    25909\nD3    23410\nA3    22655\nA2    22124\nD4    21139\nD5    17838\nE1    14064\nE2    12746\nE3    10925\nE4     9273\nE5     8653\nF1     5925\nF2     4340\nF3     3577\nF4     2859\nF5     2352\nG1     1759\nG2     1231\nG3      978\nG4      751\nG5      645\nName: subGrade, dtype: int64\n10+ years    262753\n2 years       72358\n< 1 year      64237\n3 years       64152\n1 year        52489\n5 years       50102\n4 years       47985\n6 years       37254\n8 years       36192\n7 years       35407\n9 years       30272\nName: employmentLength, dtype: int64\n2016-03-01    29066\n2015-10-01    25525\n2015-07-01    24496\n2015-12-01    23245\n2014-10-01    21461\n              ...  \n2007-08-01       23\n2007-07-01       21\n2008-09-01       19\n2007-09-01        7\n2007-06-01        1\nName: issueDate, Length: 139, dtype: int64\nAug-2001    5567\nAug-2002    5403\nSep-2003    5403\nOct-2001    5258\nAug-2000    5246\n            ... \nAug-1958       1\nAug-1955       1\nAug-1946       1\nOct-1957       1\nJan-1946       1\nName: earliesCreditLine, Length: 720, dtype: int64\n"
    }
   ],
   "source": [
    "#categorical fatures analysis\n",
    "print(category_fea)\n",
    "for fea in category_fea:\n",
    "    print(train[fea].value_counts())"
   ]
  },
  {
   "source": [
    "## Feature Engineering"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 对datatime类型数据处理"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train转化成时间格式  issueDateDT特征表示数据日期离数据集中日期最早的日期（2007-06-01）的天数\n",
    "train['issueDate'] = pd.to_datetime(train['issueDate'],format='%Y-%m-%d')\n",
    "startdate = datetime.datetime.strptime('2007-06-01', '%Y-%m-%d')\n",
    "train['issueDate'] = train['issueDate'].apply(lambda x: x-startdate).dt.days\n",
    "#testA转化成时间格式\n",
    "testA['issueDate'] = pd.to_datetime(testA['issueDate'], format='%Y-%m-%d')\n",
    "startdate = datetime.datetime.strptime('2007-06-01', '%Y-%m-%d')\n",
    "testA['issueDate'] = testA['issueDate'].apply(lambda x: x-startdate).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "label = 'isDefault'\n",
    "numerical_fea.remove(label)"
   ]
  },
  {
   "source": [
    "### 对employmentLength类型数据处理"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1 year        52489\n10+ years    262753\n2 years       72358\n3 years       64152\n4 years       47985\n5 years       50102\n6 years       37254\n7 years       35407\n8 years       36192\n9 years       30272\n< 1 year      64237\nNaN           46799\nName: employmentLength, dtype: int64"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "################################\n",
    "train['employmentLength'].value_counts(dropna=False).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deal with employmentLength\n",
    "def employmentLength_to_int(s):\n",
    "    if pd.isnull(s):\n",
    "        return s\n",
    "    else:\n",
    "        return np.int8(s.split()[0])\n",
    "#同时对test train 都进行修改\n",
    "for data in [train, testA]:\n",
    "    data['employmentLength'].replace(to_replace='10+ years', value='10 years', inplace=True)\n",
    "    data['employmentLength'].replace('< 1 year', '0 years', inplace=True)\n",
    "    data['employmentLength'] = data['employmentLength'].apply(employmentLength_to_int)"
   ]
  },
  {
   "source": [
    "### 对earliesCreditLine类型数据处理"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0         Aug-2001\n1         May-2002\n2         May-2006\n3         May-1999\n4         Aug-1977\n            ...   \n799995    Aug-2011\n799996    May-1989\n799997    Jul-2002\n799998    Jan-1994\n799999    Feb-2002\nName: earliesCreditLine, Length: 800000, dtype: object"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "train['earliesCreditLine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import calendar\n",
    "\n",
    "def time2num(d):\n",
    "    # d = d['earliesCreditLine']\n",
    "    string = d[:]\n",
    "    s1 = list(calendar.month_abbr).index(string[:3])\n",
    "    if s1 < 10: s1 = '0' + str(s1)\n",
    "    else: s1 = str(s1)\n",
    "    # print(string[-4:], s1)\n",
    "    return np.int(string[-4:] + s1)\n",
    "\n",
    "# time2num(train['earliesCreditLine'][0])\n",
    "for data in [train, testA]:\n",
    "    data['earliesCreditLine'] = data['earliesCreditLine'].apply(time2num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['id', 'loanAmnt', 'term', 'interestRate', 'installment', 'employmentTitle', 'employmentLength', 'homeOwnership', 'annualIncome', 'verificationStatus', 'issueDate', 'isDefault', 'purpose', 'postCode', 'regionCode', 'dti', 'delinquency_2years', 'ficoRangeLow', 'ficoRangeHigh', 'openAcc', 'pubRec', 'pubRecBankruptcies', 'revolBal', 'revolUtil', 'totalAcc', 'initialListStatus', 'applicationType', 'earliesCreditLine', 'title', 'policyCode', 'n0', 'n1', 'n2', 'n3', 'n4', 'n5', 'n6', 'n7', 'n8', 'n9', 'n10', 'n11', 'n12', 'n13', 'n14']\n\n['grade', 'subGrade']\n"
    }
   ],
   "source": [
    "numerical_fea = list(train.select_dtypes(exclude=['object']).columns)\n",
    "category_fea = list(filter(lambda x: x not in numerical_fea, list(train.columns)))\n",
    "print(numerical_fea, \"\\n\")\n",
    "print(category_fea)"
   ]
  },
  {
   "source": [
    "### 类型特征数据映射"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map grade object into int\n",
    "for data in [train, testA]:\n",
    "    data['grade'] = data['grade'].map({'A':0,'B':1,'C':2,'D':3,'E':4,'F':5,'G':6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train.copy()\n",
    "testA_x = testA.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "id类型数：800000\nloanAmnt类型数：1540\nterm类型数：2\ninterestRate类型数：641\ninstallment类型数：72360\ngrade类型数：7\nsubGrade类型数：35\nemploymentTitle类型数：248683\nemploymentLength类型数：11\nhomeOwnership类型数：6\nannualIncome类型数：44926\nverificationStatus类型数：3\nissueDate类型数：139\nisDefault类型数：2\npurpose类型数：14\npostCode类型数：932\nregionCode类型数：51\ndti类型数：6321\ndelinquency_2years类型数：30\nficoRangeLow类型数：39\nficoRangeHigh类型数：39\nopenAcc类型数：75\npubRec类型数：32\npubRecBankruptcies类型数：11\nrevolBal类型数：71116\nrevolUtil类型数：1286\ntotalAcc类型数：134\ninitialListStatus类型数：2\napplicationType类型数：2\nearliesCreditLine类型数：720\ntitle类型数：39644\npolicyCode类型数：1\nn0类型数：39\nn1类型数：33\nn2类型数：50\nn3类型数：50\nn4类型数：46\nn5类型数：65\nn6类型数：107\nn7类型数：70\nn8类型数：102\nn9类型数：44\nn10类型数：76\nn11类型数：5\nn12类型数：5\nn13类型数：28\nn14类型数：31\n"
    }
   ],
   "source": [
    "for f in train_x.columns:\n",
    "    print(f, '类型数：', train_x[f].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'A1': 0, 'A2': 1, 'A3': 2, 'A4': 3, 'A5': 4, 'B1': 5, 'B2': 6, 'B3': 7, 'B4': 8, 'B5': 9, 'C1': 10, 'C2': 11, 'C3': 12, 'C4': 13, 'C5': 14, 'D1': 15, 'D2': 16, 'D3': 17, 'D4': 18, 'D5': 19, 'E1': 20, 'E2': 21, 'E3': 22, 'E4': 23, 'E5': 24, 'F1': 25, 'F2': 26, 'F3': 27, 'F4': 28, 'F5': 29, 'G1': 30, 'G2': 31, 'G3': 32, 'G4': 33, 'G5': 34}\n"
    }
   ],
   "source": [
    "s = sorted(list(train_x['subGrade'].unique()))\n",
    "dict = {}\n",
    "for i, j in enumerate(s):\n",
    "    dict[j] = i\n",
    "print(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in [train_x, testA_x]:\n",
    "    data['subGrade'] = data['subGrade'].map({'A1': 0, 'A2': 1, 'A3': 2, 'A4': 3, 'A5': 4, 'B1': 5, 'B2': 6, 'B3': 7, 'B4': 8, 'B5': 9, 'C1': 10, 'C2': 11, 'C3': 12, 'C4': 13, 'C5': 14, 'D1': 15, 'D2': 16, 'D3': 17, 'D4': 18, 'D5': 19, 'E1': 20, 'E2': 21, 'E3': 22, 'E4': 23, 'E5': 24, 'F1': 25, 'F2': 26, 'F3': 27, 'F4': 28, 'F5': 29, 'G1': 30, 'G2': 31, 'G3': 32, 'G4': 33, 'G5': 34})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "term类型数：2\ngrade类型数：7\nsubGrade类型数：35\nhomeOwnership类型数：6\nverificationStatus类型数：3\npurpose类型数：14\nregionCode类型数：51\napplicationType类型数：2\ninitialListStatus类型数：2\nn11类型数：5\nn12类型数：5\n"
    }
   ],
   "source": [
    "cate_features = ['term', 'grade', 'subGrade', 'homeOwnership', 'verificationStatus', 'purpose', 'regionCode', 'applicationType', 'initialListStatus', 'n11', 'n12']\n",
    "for f in cate_features:\n",
    "    print(f, '类型数：', train_x[f].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in cate_features:\n",
    "    train_x[c] = train_x[c].astype('category')\n",
    "    testA_x[c] = testA_x[c].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "id                       int64\nloanAmnt               float64\nterm                  category\ninterestRate           float64\ninstallment            float64\ngrade                 category\nsubGrade              category\nemploymentTitle        float64\nemploymentLength       float64\nhomeOwnership         category\nannualIncome           float64\nverificationStatus    category\nissueDate                int64\nisDefault                int64\npurpose               category\npostCode               float64\nregionCode            category\ndti                    float64\ndelinquency_2years     float64\nficoRangeLow           float64\nficoRangeHigh          float64\nopenAcc                float64\npubRec                 float64\npubRecBankruptcies     float64\nrevolBal               float64\nrevolUtil              float64\ntotalAcc               float64\ninitialListStatus     category\napplicationType       category\nearliesCreditLine        int64\ntitle                  float64\npolicyCode             float64\nn0                     float64\nn1                     float64\nn2                     float64\nn3                     float64\nn4                     float64\nn5                     float64\nn6                     float64\nn7                     float64\nn8                     float64\nn9                     float64\nn10                    float64\nn11                   category\nn12                   category\nn13                    float64\nn14                    float64\ndtype: object"
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "train_x.dtypes"
   ]
  },
  {
   "source": [
    "## Build model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [f for f in train_x.columns if f not in ['id', 'isDefault', 'issueDate', 'policyCode']]\n",
    "\n",
    "x_train = train_x[features]\n",
    "x_test = testA_x[features]\n",
    "\n",
    "y_train = train_x['isDefault']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_model(clf, train_x, train_y, test_x, clf_name, categorical_feats=''):\n",
    "    folds = 5\n",
    "    seed = 2020\n",
    "    kf = KFold(n_splits=folds, shuffle=True, random_state=seed)\n",
    "\n",
    "    train = np.zeros(train_x.shape[0])\n",
    "    test = np.zeros(test_x.shape[0])\n",
    "\n",
    "    cv_scores = []\n",
    "\n",
    "    for i, (train_index, valid_index) in enumerate(kf.split(train_x, train_y)):\n",
    "        print('************************************ {} ************************************'.format(str(i+1)))\n",
    "        trn_x, trn_y, val_x, val_y = train_x.iloc[train_index], train_y[train_index], train_x.iloc[valid_index], train_y[valid_index]\n",
    "\n",
    "        if clf_name == \"lgb\":\n",
    "            train_matrix = clf.Dataset(trn_x, label=trn_y, categorical_feature=categorical_feats)\n",
    "            valid_matrix = clf.Dataset(val_x, label=val_y, categorical_feature=categorical_feats)\n",
    "\n",
    "            # params = {\n",
    "            #     'boosting_type': 'gbdt',\n",
    "            #     'objective': 'binary',\n",
    "            #     'metric': 'auc',\n",
    "            #     'min_child_weight': 5,\n",
    "            #     'num_leaves': 2 ** 5,\n",
    "            #     'lambda_l2': 10,\n",
    "            #     'feature_fraction': 0.8,\n",
    "            #     'bagging_fraction': 0.8,\n",
    "            #     'bagging_freq': 4,\n",
    "            #     'learning_rate': 0.1,\n",
    "            #     'seed': 2020,\n",
    "            #     'nthread': 28,\n",
    "            #     'n_jobs':24,\n",
    "            #     'silent': True,\n",
    "            #     'verbose': -1,\n",
    "            # }\n",
    "            \n",
    "            #调整过的参数\n",
    "            params = {\n",
    "                'boosting_type': 'gbdt',\n",
    "                'objective': 'binary',\n",
    "                'metric': 'auc',\n",
    "                'learning_rate': 0.01,\n",
    "                'num_leaves': 14,\n",
    "                'max_depth': 19,\n",
    "                'min_data_in_leaf': 37,\n",
    "                'min_child_weight':1.6,\n",
    "                'bagging_fraction': 0.98,\n",
    "                'feature_fraction': 0.69,\n",
    "                'bagging_freq': 96,\n",
    "                'reg_lambda': 9,\n",
    "                'reg_alpha': 7,\n",
    "                'min_split_gain': 0.4,\n",
    "                'nthread': 8,\n",
    "                'seed': 2020,\n",
    "                'silent': True\n",
    "    }\n",
    "\n",
    "            model = clf.train(params, train_matrix, num_boost_round=15000, valid_sets=[train_matrix, valid_matrix], verbose_eval=1000,early_stopping_rounds=200)\n",
    "            val_pred = model.predict(val_x, num_iteration=model.best_iteration)\n",
    "            test_pred = model.predict(test_x, num_iteration=model.best_iteration)\n",
    "            \n",
    "            # print(list(sorted(zip(features, model.feature_importance(\"gain\")), key=lambda x: x[1], reverse=True))[:20])\n",
    "                \n",
    "        if clf_name == \"xgb\":\n",
    "            train_matrix = clf.DMatrix(trn_x , label=trn_y)\n",
    "            valid_matrix = clf.DMatrix(val_x , label=val_y)\n",
    "            test_matrix = clf.DMatrix(test_x)\n",
    "            \n",
    "            params = {'booster': 'gbtree',\n",
    "                      'objective': 'binary:logistic',\n",
    "                      'eval_metric': 'auc',\n",
    "                      'gamma': 1,\n",
    "                      'min_child_weight': 1.5,\n",
    "                      'max_depth': 5,\n",
    "                      'lambda': 10,\n",
    "                      'subsample': 0.7,\n",
    "                      'colsample_bytree': 0.7,\n",
    "                      'colsample_bylevel': 0.7,\n",
    "                      'eta': 0.04,\n",
    "                      'tree_method': 'exact',\n",
    "                      'seed': 2020,\n",
    "                      'nthread': 36,\n",
    "                      \"silent\": True,\n",
    "                      'device': 'gpu'\n",
    "                      }\n",
    "            \n",
    "            watchlist = [(train_matrix, 'train'),(valid_matrix, 'eval')]\n",
    "            \n",
    "            model = clf.train(params, train_matrix, num_boost_round=50000, evals=watchlist, verbose_eval=200, early_stopping_rounds=200)\n",
    "            val_pred  = model.predict(valid_matrix, ntree_limit=model.best_ntree_limit)\n",
    "            test_pred = model.predict(test_matrix , ntree_limit=model.best_ntree_limit)\n",
    "                 \n",
    "        if clf_name == \"cat\":\n",
    "            # params = {'learning_rate': 0.05, 'depth': 5, 'l2_leaf_reg': 10, 'bootstrap_type': 'Bernoulli',\n",
    "            #           'od_type': 'Iter', 'od_wait': 50, 'random_seed': 11, 'allow_writing_files': False}\n",
    "            # params = {'learning_rate' : 0.03, 'depth': 7, 'l2_leaf_reg': 3, 'bootstrap_type': 'Bernoulli',\n",
    "            #           'od_type': 'Iter', 'od_wait': 50, 'random_seed': 11, 'task_type':'GPU', 'allow_writing_files': False}\n",
    "            params = {'learning_rate':0.03, 'depth': 9, 'l2_leaf_reg': 3, 'bootstrap_type': 'Bernoulli',\n",
    "                      'od_type': 'Iter', 'random_seed': 42, 'task_type': 'GPU', 'allow_writing_files': False}\n",
    "            \n",
    "            model = clf(iterations=20000, **params)\n",
    "            model.fit(trn_x, trn_y, eval_set=(val_x, val_y),\n",
    "                      cat_features=[], use_best_model=True, verbose=500)\n",
    "            \n",
    "            val_pred  = model.predict(val_x)\n",
    "            test_pred = model.predict(test_x)\n",
    "            \n",
    "        train[valid_index] = val_pred\n",
    "        test = test_pred / kf.n_splits\n",
    "        cv_scores.append(roc_auc_score(val_y, val_pred))\n",
    "        \n",
    "        print(cv_scores)\n",
    "       \n",
    "    print(\"%s_scotrainre_list:\" % clf_name, cv_scores)\n",
    "    print(\"%s_score_mean:\" % clf_name, np.mean(cv_scores))\n",
    "    print(\"%s_score_std:\" % clf_name, np.std(cv_scores))\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_model(x_train, y_train, x_test, cate_features):\n",
    "    lgb_train, lgb_test = cv_model(lgb, x_train, y_train, x_test, \"lgb\", cate_features)\n",
    "    return lgb_train, lgb_test\n",
    "\n",
    "def xgb_model(x_train, y_train, x_test):\n",
    "    xgb_train, xgb_test = cv_model(xgb, x_train, y_train, x_test, \"xgb\")\n",
    "    return xgb_train, xgb_test\n",
    "\n",
    "def cat_model(x_train, y_train, x_test):\n",
    "    cat_train, cat_test = cv_model(CatBoostRegressor, x_train, y_train, x_test, \"cat\") \n",
    "    return cat_train, cat_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_train, lgb_test = lgb_model(x_train, y_train, x_test,  cate_features)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rh_test =lgb_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testA['isDefault'] = rh_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testA[['id','isDefault']].to_csv('lgb_sub.csv', index=False)"
   ]
  }
 ]
}